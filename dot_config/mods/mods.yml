# OpenAI compatible REST API (openai, localai, anthropic, ...)
default-api: groq
default-model: meta-llama/llama-4-scout-17b-16e-instruct
format-text:
  markdown: "Format the response as markdown without enclosing backticks."
  json: "Format the response as json without enclosing backticks. Do not enclose the response in backticks."
  bash: "Format the response as bash without enclosing backticks."
# MCP Servers configurations
mcp-servers:
  # Alternative: Direct command execution (when Docker containers are not running)
  # github-direct:
  #   command: docker
  #   args:
  #     - run
  #     - "-i"
  #     - "--rm"
  #     - "-e"
  #     - GITHUB_PERSONAL_ACCESS_TOKEN
  #     - "ghcr.io/github/github-mcp-server"
  # ref-direct:
  #   command: npx
  #   args:
  #     - ref-tools-mcp@latest
  # filesystem-direct:
  #   command: npx
  #   args:
  #     - "-y"
  #     - "@modelcontextprotocol/server-filesystem"
  #     - "/home/prad/code/github.com/sonr-io/sonr"
  #     - "/home/prad/code/github.com/go-sonr/ui"
  #     - "/home/prad/Notes"
  # obsidian-direct:
  #   command: uvx
  #   args:
  #     - mcp-obsidian
  #   env:
  #     OBSIDIAN_API_KEY: "${OBSIDIAN_API_KEY}"
  #     OBSIDIAN_HOST: "${OBSIDIAN_HOST}"
  #     OBSIDIAN_PORT: "${OBSIDIAN_PORT}"
  # sequentialthinking-direct:
  #   command: npx
  #   args:
  #     - "-y"
  #     - "@modelcontextprotocol/server-sequential-thinking"
# Timeout for MCP server calls, defaults to 15 seconds
mcp-timeout: 15s
# List of predefined system messages that can be used as roles
roles:
  "default": []
  "pr-writer":
    - You are a PR description writer
    - Create clear, structured PR descriptions
    - Include all relevant context from commits and changes
    - Format using markdown with proper sections
    - Reference issues and milestones appropriately
    - Be concise but comprehensive
    - Include a testing checklist if relevant
  "commit-writer":
    - |
          Please suggest 10 commit messages, given the following diff:

          ```diff
          {{diff}}
          ```

          Criteria:

          1. Format: Each commit message must follow the conventional commits format with scope: <type>(<scope>): <description>
          • Types: feat, fix, docs, style, refactor, test, perf, build, ci, chore
          • Scopes: Use one of the following based on changed files:
            • core - Core blockchain changes (cmd/snrd/, app/)
            • hway - Highway service changes (cmd/hway/, bridge/)
            • motr - Motor WASM plugin changes (cmd/motr/**)
            • vault - Vault system changes (cmd/vault/**)
            • dex - DEX module changes (x/dex/, proto/dex/)
            • did - DID module changes (x/did/, proto/did/)
            • dwn - DWN module changes (x/dwn/, proto/dwn/)
            • svc - Service module changes (x/svc/, proto/svc/)
            • client - Client library changes
            • crypto - Cryptography changes
            • pkg-es - ES package changes (packages/es/**)
            • pkg-sdk - SDK package changes (packages/sdk/**)
            • pkg-ui - UI components (packages/ui/**)
            • web-auth - Auth app changes (web/auth/**)
            • web-dash - Dashboard app changes (web/dash/**)
            • docs - Documentation changes
            • devops - CI/CD and infrastructure (.github/, scripts/)

          2. Scope Selection: Choose the most specific scope that matches the primary focus of the changes. If changes span multiple scopes, use the most
          impactful one.
          3. Breaking Changes: For breaking changes, add ! after the scope: <type>(<scope>)!: <description>
          4. Enumeration: List the commit messages from 1 to 10.
          5. Clarity and Conciseness: Each message should clearly convey the change's impact, not just describe what was modified.

          Commit Message Examples:

          • fix(core): resolve consensus timeout during high load
          • feat(did): add WebAuthn biometric authentication support
          • refactor(hway): extract Redis connection pooling to shared utility
          • perf(vault): optimize IPFS chunk size for large file uploads
          • build(devops): update CI pipeline for parallel module testing
          • docs(dwn): clarify data retention policies in API reference
          • test(svc): add integration tests for domain verification flow
          • fix(pkg-ui)!: rename Button prop 'type' to 'variant' (breaking)

          Instructions:

          • Analyze the diff to understand which files/directories are affected
          • Map the file paths to the appropriate scope(s) from the list above
          • Consider the business impact and user-facing effects of the changes
          • Ensure variety in your suggestions - cover different interpretations of the changes
          • Focus on the "why" and "what effect" rather than just "what changed"
          • For breaking changes that affect APIs or interfaces, include the ! marker
          • Remember that only one message will be used, so provide diverse options that capture different aspects

          Write your 10 commit messages below in JSON list format:

          {
            "commitMessages": [
              "type(scope): description",
              "type(scope): description"
            ]
          }
    - NEVER explain anything
    - NEVER print your thoughts
    - NEVER include markdown code blocks
    - NEVER print any other text
    - ONLY return the JSON list format
  "commit-analyzer":
    - Analyze git diffs to determine the primary type of change
    - Identify if changes are features, fixes, refactoring, etc
    - Summarize the key changes in a structured format
    - Output a JSON object with type, scope, description, and body fields

  "crawl-extractor":
    - you are a highly advanced "crawl-extractor"
    - Given a list of urls for a website, you return a list of all the links which would contain readable text
    - You must return each url as a separate line
    - You must not return any other text
    - If the url is not readable, you must return nothing
  "branch-namer":
    - you are a branch namer
    - you do not explain anything
    - you read the provided issue and body then create a title for the branch
    - you do not provide any explanation whatsoever, ONLY the title
    - titles must be no more than 3 words (example = feature/add-new-feature)
    - ONLY use the following format - feat/<feature-name>
  "rg-assistant":
    - you are a shell command generator for the rg tool.
    - you do not explain anything. DO NOT PRINT YOUR THOUGHTS.
    - you only return with commands that follow the syntax of the rg tool specified in its help command.
    - |
      Here is the help for the rg tool:

      rg -h
      ripgrep 14.1.1
      Andrew Gallant <jamslam@gmail.com>

      ripgrep (rg) recursively searches the current directory for lines matching
      a regex pattern. By default, ripgrep will respect gitignore rules and
      automatically skip hidden files/directories and binary files.

      Use -h for short descriptions and --help for more details.

      Project home page: https://github.com/BurntSushi/ripgrep

      USAGE:
        rg [OPTIONS] PATTERN [PATH ...]

      POSITIONAL ARGUMENTS:
        <PATTERN>   A regular expression used for searching.
        <PATH>...   A file or directory to search.

      INPUT OPTIONS:
        -e, --regexp=PATTERN            A pattern to search for.
        -f, --file=PATTERNFILE          Search for patterns from the given file.
        --pre=COMMAND                   Search output of COMMAND for each PATH.
        --pre-glob=GLOB                 Include or exclude files from a preprocessor.
        -z, --search-zip                Search in compressed files.

      SEARCH OPTIONS:
        -s, --case-sensitive            Search case sensitively (default).
        --crlf                          Use CRLF line terminators (nice for Windows).
        --dfa-size-limit=NUM            The upper size limit of the regex DFA.
        -E, --encoding=ENCODING         Specify the text encoding of files to search.
        --engine=ENGINE                 Specify which regex engine to use.
        -F, --fixed-strings             Treat all patterns as literals.
        -i, --ignore-case               Case insensitive search.
        -v, --invert-match              Invert matching.
        -x, --line-regexp               Show matches surrounded by line boundaries.
        -m, --max-count=NUM             Limit the number of matching lines.
        --mmap                          Search with memory maps when possible.
        -U, --multiline                 Enable searching across multiple lines.
        --multiline-dotall              Make '.' match line terminators.
        --no-unicode                    Disable Unicode mode.
        --null-data                     Use NUL as a line terminator.
        -P, --pcre2                     Enable PCRE2 matching.
        --regex-size-limit=NUM          The size limit of the compiled regex.
        -S, --smart-case                Smart case search.
        --stop-on-nonmatch              Stop searching after a non-match.
        -a, --text                      Search binary files as if they were text.
        -j, --threads=NUM               Set the approximate number of threads to use.
        -w, --word-regexp               Show matches surrounded by word boundaries.
        --auto-hybrid-regex             (DEPRECATED) Use PCRE2 if appropriate.
        --no-pcre2-unicode              (DEPRECATED) Disable Unicode mode for PCRE2.

      FILTER OPTIONS:
        --binary                        Search binary files.
        -L, --follow                    Follow symbolic links.
        -g, --glob=GLOB                 Include or exclude file paths.
        --glob-case-insensitive         Process all glob patterns case insensitively.
        -., --hidden                    Search hidden files and directories.
        --iglob=GLOB                    Include/exclude paths case insensitively.
        --ignore-file=PATH              Specify additional ignore files.
        --ignore-file-case-insensitive  Process ignore files case insensitively.
        -d, --max-depth=NUM             Descend at most NUM directories.
        --max-filesize=NUM              Ignore files larger than NUM in size.
        --no-ignore                     Don't use ignore files.
        --no-ignore-dot                 Don't use .ignore or .rgignore files.
        --no-ignore-exclude             Don't use local exclusion files.
        --no-ignore-files               Don't use --ignore-file arguments.
        --no-ignore-global              Don't use global ignore files.
        --no-ignore-parent              Don't use ignore files in parent directories.
        --no-ignore-vcs                 Don't use ignore files from source control.
        --no-require-git                Use .gitignore outside of git repositories.
        --one-file-system               Skip directories on other file systems.
        -t, --type=TYPE                 Only search files matching TYPE.
        -T, --type-not=TYPE             Do not search files matching TYPE.
        --type-add=TYPESPEC             Add a new glob for a file type.
        --type-clear=TYPE               Clear globs for a file type.
        -u, --unrestricted              Reduce the level of "smart" filtering.

      OUTPUT OPTIONS:
        -A, --after-context=NUM         Show NUM lines after each match.
        -B, --before-context=NUM        Show NUM lines before each match.
        --block-buffered                Force block buffering.
        -b, --byte-offset               Print the byte offset for each matching line.
        --color=WHEN                    When to use color.
        --colors=COLOR_SPEC             Configure color settings and styles.
        --column                        Show column numbers.
        -C, --context=NUM               Show NUM lines before and after each match.
        --context-separator=SEP         Set the separator for contextual chunks.
        --field-context-separator=SEP   Set the field context separator.
        --field-match-separator=SEP     Set the field match separator.
        --heading                       Print matches grouped by each file.
        -h, --help                      Show help output.
        --hostname-bin=COMMAND          Run a program to get this system's hostname.
        --hyperlink-format=FORMAT       Set the format of hyperlinks.
        --include-zero                  Include zero matches in summary output.
        --line-buffered                 Force line buffering.
        -n, --line-number               Show line numbers.
        -N, --no-line-number            Suppress line numbers.
        -M, --max-columns=NUM           Omit lines longer than this limit.
        --max-columns-preview           Show preview for lines exceeding the limit.
        -0, --null                      Print a NUL byte after file paths.
        -o, --only-matching             Print only matched parts of a line.
        --path-separator=SEP            Set the path separator for printing paths.
        --passthru                      Print both matching and non-matching lines.
        -p, --pretty                    Alias for colors, headings and line numbers.
        -q, --quiet                     Do not print anything to stdout.
        -r, --replace=TEXT              Replace matches with the given text.
        --sort=SORTBY                   Sort results in ascending order.
        --sortr=SORTBY                  Sort results in descending order.
        --trim                          Trim prefix whitespace from matches.
        --vimgrep                       Print results in a vim compatible format.
        -H, --with-filename             Print the file path with each matching line.
        -I, --no-filename               Never print the path with each matching line.
        --sort-files                    (DEPRECATED) Sort results by file path.

      OUTPUT MODES:
        -c, --count                     Show count of matching lines for each file.
        --count-matches                 Show count of every match for each file.
        -l, --files-with-matches        Print the paths with at least one match.
        --files-without-match           Print the paths that contain zero matches.
        --json                          Show search results in a JSON Lines format.

      LOGGING OPTIONS:
        --debug                         Show debug messages.
        --no-ignore-messages            Suppress gitignore parse error messages.
        --no-messages                   Suppress some error messages.
        --stats                         Print statistics about the search.
        --trace                         Show trace messages.

      OTHER BEHAVIORS:
        --files                         Print each file that would be searched.
        --generate=KIND                 Generate man pages and completion scripts.
        --no-config                     Never read configuration files.
        --pcre2-version                 Print the version of PCRE2 that ripgrep uses.
        --type-list                     Show all supported file types.
        -V, --version                   Print ripgrep's version.
    - you read the user provided query and the directory structure they are in
    - you then generate a shell command that will search for the provided query in the current directory and its subdirectories
  "issue-creator":
    - you are an advanced issue creator for github in the sonr-io org
    - you are provided an input in the format of - <repo-name>:<issue-context>
    - you do not explain anything
    - you read the short provided context for a new issue and then create an appropriate issue body
    - ALWAYS find relevant context by using the `mcp::ref::ref_search_documentation` tool
    - ALWAYS link relevant issues by using the `mcp::github::search_issues` tool
    - ALWAYS create a new issue in the sonr-io/<repo-name> repo
    - ALWAYS assign the issue to @prnk28
    - |
      ONLY use the following format as this example:

      Title: Implement x/dwn vaults plugin
      Labels: x/dwn, feature

      ## Requirements

      - Must include DWN Bytes in Protobuf
      - Must Spawn DWN Plugins using Genesis Params
      - Must have Gas Free Query Methods for Spawn and Verify

      ## Context

      ### Affected Files

      - @x/dwn/keeper/keeper.go
      - @x/dwn/client/wasm/main.go
      - @x/dwn/types/genesis.go

      ### Relevant Documentation

      - [Example Doc 1](https://example.com)
      - [Example Doc 2](https://example.com)

      ## Acceptance Criteria

      - [ ] Tests for Spawning Plugins from the x/dwn Genesis
      - [ ] Tests for Resolving Vault Secret Data from IPFS
      - [ ] Test for full-round Sign/Verify/Refresh on-chain
      - [ ] Grpc Gateway Compatibility for HTTP Requests
    - ALWAYS create issues using the `mcp::github::create_issue` tool
    - ALWAYS return the issue number after creating a new issue
# Ask for the response to be formatted as markdown unless otherwise set
format: false
role: "branch-namer"
# Render output as raw text when connected to a TTY
raw: true
quiet: true
# Temperature (randomness) of results, from 0.0 to 2.0, -1.0 to disable
temp: 1.0
# TopP, an alternative to temperature that narrows response, from 0.0 to 1.0, -1.0 to disable
topp: 1.0
# TopK, only sample from the top K options for each subsequent token, -1 to disable
topk: 50
# Turn off the client-side limit on the size of the input into the model
no-limit: true
# Wrap formatted output at specific width (default is 80)
word-wrap: 80
# Include the prompt from the arguments in the response
include-prompt-args: false
# Include the prompt from the arguments and stdin, truncate stdin to specified number of lines
include-prompt: 0
# Maximum number of times to retry API calls
max-retries: 5
# Your desired level of fanciness
fanciness: 10
# Text to show while generating
status-text: Generating
# Theme to use in the forms; valid choices are charm, catppuccin, dracula, and base16
theme: base16
# Default character limit on input to model
max-input-chars: 12250
# Maximum number of tokens in response
# max-tokens: 100
#
max-completion-tokens: 100
# Aliases and endpoints for OpenAI compatible REST API
apis:
  openai:
    base-url: https://api.openai.com/v1
    api-key:
    api-key-env: OPENAI_API_KEY
    # api-key-cmd: rbw get -f OPENAI_API_KEY chat.openai.com
    models: # https://platform.openai.com/docs/models
      gpt-4.5-preview: #128k https://platform.openai.com/docs/models/gpt-4.5-preview
        aliases: ["gpt-4.5", "gpt4.5"]
        max-input-chars: 392000
        fallback: gpt-4
      gpt-4.5-preview-2025-02-27:
        max-input-chars: 392000
        fallback: gpt-4
      gpt-4o-mini:
        aliases: ["4o-mini"]
        max-input-chars: 392000
        fallback: gpt-4o
      gpt-4o:
        aliases: ["4o"]
        max-input-chars: 392000
        fallback: gpt-4
      gpt-4:
        aliases: ["4"]
        max-input-chars: 24500
        fallback: gpt-3.5-turbo
      gpt-4-1106-preview:
        aliases: ["128k"]
        max-input-chars: 392000
        fallback: gpt-4
      gpt-4-32k:
        aliases: ["32k"]
        max-input-chars: 98000
        fallback: gpt-4
      gpt-3.5-turbo:
        aliases: ["35t"]
        max-input-chars: 12250
        fallback: gpt-3.5
      gpt-3.5-turbo-1106:
        aliases: ["35t-1106"]
        max-input-chars: 12250
        fallback: gpt-3.5-turbo
      gpt-3.5-turbo-16k:
        aliases: ["35t16k"]
        max-input-chars: 44500
        fallback: gpt-3.5
      gpt-3.5:
        aliases: ["35"]
        max-input-chars: 12250
        fallback:
      o1:
        aliases: ["o1"]
        max-input-chars: 200000
      o1-preview:
        aliases: ["o1-preview"]
        max-input-chars: 128000
      o1-mini:
        aliases: ["o1-mini"]
        max-input-chars: 128000
      o3-mini:
        aliases: ["o3m", "o3-mini"]
        max-input-chars: 200000
  copilot:
    base-url: https://api.githubcopilot.com
    models:
      gpt-4o-2024-05-13:
        aliases: ["4o-2024", "4o", "gpt-4o"]
        max-input-chars: 392000
      gpt-4:
        aliases: ["4"]
        max-input-chars: 24500
      gpt-3.5-turbo:
        aliases: ["35t"]
        max-input-chars: 12250
      o1-preview-2024-09-12:
        aliases: ["o1-preview", "o1p"]
        max-input-chars: 128000
      claude-3.5-sonnet:
        aliases: ["claude3.5-sonnet", "sonnet-3.5", "claude-3-5-sonnet"]
        max-input-chars: 680000
      o1-preview:
        aliases: ["o1-preview"]
        max-input-chars: 128000
      o1-mini:
        aliases: ["o1-mini", "o1m", "o1-mini-2024-09-12"]
        max-input-chars: 128000
      o3-mini:
        aliases: ["o3m", "o3-mini"]
        max-input-chars: 128000
      gemini-2.0-flash-001:
        aliases: ["gm2f", "flash-2", "gemini-2-flash"]
        max-input-chars: 4194304
  anthropic:
    base-url: https://api.anthropic.com/v1
    api-key:
    api-key-env: ANTHROPIC_API_KEY
    models: # https://docs.anthropic.com/en/docs/about-claude/models
      claude-sonnet-4-20250514:
        aliases: ["claude-sonnet-4", "sonnet-4"]
        max-input-chars: 680000
      claude-3-7-sonnet-latest:
        aliases: ["claude3.7-sonnet", "claude-3-7-sonnet", "sonnet-3.7"]
        max-input-chars: 680000
      claude-3-7-sonnet-20250219:
        max-input-chars: 680000
      claude-3-5-sonnet-latest:
        aliases: ["claude3.5-sonnet", "claude-3-5-sonnet", "sonnet-3.5"]
        max-input-chars: 680000
      claude-3-5-sonnet-20241022:
        max-input-chars: 680000
      claude-3-5-sonnet-20240620:
        max-input-chars: 680000
      claude-3-opus-20240229:
        aliases: ["claude3-opus", "opus"]
        max-input-chars: 680000
  cohere:
    base-url: https://api.cohere.com/v1
    models:
      command-r-plus:
        max-input-chars: 128000
      command-r:
        max-input-chars: 128000
  google:
    models: # https://ai.google.dev/gemini-api/docs/models/gemini
      gemini-1.5-pro-latest:
        aliases: ["gmp", "gemini", "gemini-1.5-pro"]
        max-input-chars: 392000
      gemini-1.5-flash-latest:
        aliases: ["gmf", "flash", "gemini-1.5-flash"]
        max-input-chars: 392000
      gemini-2.0-flash-001:
        aliases: ["gm2f", "flash-2", "gemini-2-flash"]
        max-input-chars: 4194304
      gemini-2.0-flash-lite:
        aliases: ["gm2fl", "flash-2-lite", "gemini-2-flash-lite"]
        max-input-chars: 4194304
  ollama:
    base-url: http://localhost:11434
    models: # https://ollama.com/library
      "llama3.2:3b":
        aliases: ["llama3.2"]
        max-input-chars: 650000
      "llama3.2:1b":
        aliases: ["llama3.2_1b"]
        max-input-chars: 650000
      "llama3:70b":
        aliases: ["llama3"]
        max-input-chars: 650000
  perplexity:
    base-url: https://api.perplexity.ai
    api-key:
    api-key-env: PERPLEXITY_API_KEY
    models: # https://docs.perplexity.ai/guides/model-cards
      llama-3.1-sonar-small-128k-online:
        aliases: ["llam31-small"]
        max-input-chars: 127072
      llama-3.1-sonar-large-128k-online:
        aliases: ["llam31-large"]
        max-input-chars: 127072
      llama-3.1-sonar-huge-128k-online:
        aliases: ["llam31-huge"]
        max-input-chars: 127072
  groq:
    base-url: https://api.groq.com/openai/v1
    api-key:
    api-key-env: GROQ_API_KEY
    models: # https://console.groq.com/docs/models
      # Production models
      gemma2-9b-it:
        aliases: ["gemma2", "gemma"]
        max-input-chars: 24500 # 8,192
      llama-3.3-70b-versatile:
        aliases: ["llama3.3", "llama3.3-70b", "llama3.3-versatile"]
        max-input-chars: 392000 # 128K
        max-completion-tokens: 98000 # 32,768
      llama-3.1-8b-instant:
        aliases: ["llama3.1-8b", "llama3.1-instant"]
        max-input-chars: 392000 # 128K
        max-completion-tokens: 24500 # 8,192
      llama-guard-3-8b:
        aliases: ["llama-guard"]
        max-input-chars: 24500 # 8,192
      llama3-70b-8192:
        aliases: ["llama3", "llama3-70b"]
        max-input-chars: 24500 # 8,192
        fallback: llama3-8b-8192
      llama3-8b-8192:
        aliases: ["llama3-8b"]
        max-input-chars: 24500 # 8,192
      mixtral-8x7b-32768:
        aliases: ["mixtral"]
        max-input-chars: 98000 # 32,768
      meta-llama/llama-4-scout-17b-16e-instruct:
        aliases: ["llama4-scout"]
        max-input-chars: 392000 # 128K
      meta-llama/llama-4-maverick-17b-128e-instruct:
        aliases: ["llama4", "llama4-maverick"]
        max-input-chars: 392000 # 128K
      # Preview models
      mistral-saba-24b:
        aliases: ["saba", "mistral-saba", "saba-24b"]
        max-input-chars: 98000 # 32K
      qwen-2.5-coder-32b:
        aliases: ["qwen-coder", "qwen2.5-coder", "qwen-2.5-coder"]
        max-input-chars: 392000 # 128K
      qwen/qwen3-32b:
        aliases: ["qwen3", "qwen3-32b"]
        max-input-chars: 392000 # 128K
      deepseek-r1-distill-qwen-32b:
        aliases: ["deepseek-r1", "r1-qwen", "deepseek-qwen"]
        max-input-chars: 392000 # 128K
        max-completion-tokens: 49152 # 16,384
      deepseek-r1-distill-llama-70b-specdec:
        aliases: ["deepseek-r1-specdec", "r1-llama-specdec"]
        max-input-chars: 392000 # 128K
        max-completion-tokens: 49152 # 16,384
      deepseek-r1-distill-llama-70b:
        aliases: ["deepseek-r1-llama", "r1-llama"]
        max-input-chars: 392000 # 128K
      llama-3.3-70b-specdec:
        aliases: ["llama3.3-specdec"]
        max-input-chars: 24500 # 8,192
      llama-3.2-1b-preview:
        aliases: ["llama3.2-1b"]
        max-input-chars: 392000 # 128K
        max-completion-tokens: 24500 # 8,192
      llama-3.2-3b-preview:
        aliases: ["llama3.2-3b"]
        max-input-chars: 392000 # 128K
        max-completion-tokens: 24500 # 8,192
      llama-3.2-11b-vision-preview:
        aliases: ["llama3.2-vision", "llama3.2-11b-vision"]
        max-input-chars: 392000 # 128K
        max-completion-tokens: 24500 # 8,192
      llama-3.2-90b-vision-preview:
        aliases: ["llama3.2-90b-vision"]
        max-input-chars: 392000 # 128K
        max-completion-tokens: 24500 # 8,192
  cerebras:
    base-url: https://api.cerebras.ai/v1
    api-key:
    api-key-env: CEREBRAS_API_KEY
    models: # https://inference-docs.cerebras.ai/introduction
      llama-4-maverick-17b-128e-instruct:
        aliases: ["cerberus-llama"]
        max-input-chars: 24500
      qwen-3-coder-480b:
        aliases: ["cerberus-qwen"]
        max-input-chars: 24500
  sambanova:
    base-url: https://api.sambanova.ai/v1
    api-key:
    api-key-env: SAMBANOVA_API_KEY
    models: # https://docs.sambanova.ai/cloud/docs/get-started/supported-models
      # Preview models
      DeepSeek-R1:
        aliases: ["deepseek-r1-sambanova", "deepseek-r1-preview"]
        max-input-chars: 24500 # 8k tokens
      # Production models
      DeepSeek-R1-Distill-Llama-70B:
        aliases: ["deepseek-r1-llama-sambanova", "deepseek-r1-distill"]
        max-input-chars: 98000 # 32k tokens
      Llama-3.1-Tulu-3-405B:
        aliases: ["llama3.1-tulu", "tulu-405b"]
        max-input-chars: 49000 # 16k tokens
      Meta-Llama-3.3-70B-Instruct:
        aliases: ["llama3.3-sambanova", "llama3.3-70b-sambanova"]
        max-input-chars: 392000 # 128k tokens
      Meta-Llama-3.2-3B-Instruct:
        aliases: ["llama3.2-3b-sambanova"]
        max-input-chars: 24500 # 8k tokens
      Meta-Llama-3.2-1B-Instruct:
        aliases: ["llama3.2-1b-sambanova"]
        max-input-chars: 49000 # 16k tokens
      Meta-Llama-3.1-405B-Instruct:
        aliases: ["llama3.1-405b-sambanova"]
        max-input-chars: 49000 # 16k tokens
      Meta-Llama-3.1-70B-Instruct:
        aliases: ["llama3.1-70b-sambanova"]
        max-input-chars: 392000 # 128k tokens
      Meta-Llama-3.1-8B-Instruct:
        aliases: ["llama3.1-8b-sambanova"]
        max-input-chars: 49000 # 16k tokens
      Meta-Llama-Guard-3-8B:
        aliases: ["llama-guard-sambanova"]
        max-input-chars: 24500 # 8k tokens
      Llama-3.2-90B-Vision-Instruct:
        aliases: ["llama3.2-vision-90b", "llama3.2-90b-vision-sambanova"]
        max-input-chars: 12250 # 4k tokens
      Llama-3.2-11B-Vision-Instruct:
        aliases: ["llama3.2-vision-11b", "llama3.2-11b-vision-sambanova"]
        max-input-chars: 12250 # 4k tokens
      Qwen2.5-72B-Instruct:
        aliases: ["qwen2.5-sambanova", "qwen2.5-72b"]
        max-input-chars: 49000 # 16k tokens
      Qwen2.5-Coder-32B-Instruct:
        aliases: ["qwen2.5-coder-sambanova", "qwen-coder-sambanova"]
        max-input-chars: 49000 # 16k tokens
      QwQ-32B-Preview:
        aliases: ["qwq-sambanova", "qwq-32b"]
        max-input-chars: 49000 # 16k tokens
  localai:
    # LocalAI setup instructions: https://github.com/go-skynet/LocalAI#example-use-gpt4all-j-model
    base-url: http://localhost:8080
    models:
      ggml-gpt4all-j:
        aliases: ["local", "4all"]
        max-input-chars: 12250
        fallback:
  azure:
    # Set to 'azure-ad' to use Active Directory
    # Azure OpenAI setup: https://learn.microsoft.com/en-us/azure/cognitive-services/openai/how-to/create-resource
    base-url: https://YOUR_RESOURCE_NAME.openai.azure.com
    api-key:
    api-key-env: AZURE_OPENAI_KEY
    models:
      gpt-4:
        aliases: ["az4"]
        max-input-chars: 24500
        fallback: gpt-35-turbo
      gpt-35-turbo:
        aliases: ["az35t"]
        max-input-chars: 12250
        fallback: gpt-35
      gpt-35:
        aliases: ["az35"]
        max-input-chars: 12250
        fallback:
      o1-preview:
        aliases: ["o1-preview"]
        max-input-chars: 128000
      o1-mini:
        aliases: ["o1-mini"]
        max-input-chars: 128000
  runpod:
    # https://docs.runpod.io/serverless/workers/vllm/openai-compatibility
    base-url: https://api.runpod.ai/v2/${YOUR_ENDPOINT}/openai/v1
    api-key:
    api-key-env: RUNPOD_API_KEY
    models:
      openchat/openchat-3.5-1210:
        aliases: ["openchat"]
        max-input-chars: 8192
  mistral:
    base-url: https://api.mistral.ai/v1
    api-key:
    api-key-env: MISTRAL_API_KEY
    models: # https://docs.mistral.ai/getting-started/models/
      mistral-large-latest:
        aliases: ["mistral-large"]
        max-input-chars: 384000
      open-mistral-nemo:
        aliases: ["mistral-nemo"]
        max-input-chars: 384000
  cerberus:
    base-url: https://api.cerberus.ai/v1
    api-key:
    api-key-env: CERBERUS_API_KEY
    models: # https://docs.mistral.ai/getting-started/models/
      mistral-large-latest:
        aliases: ["mistral-large"]
        max-input-chars: 384000
      open-mistral-nemo:
        aliases: ["mistral-nemo"]
        max-input-chars: 384000
  # DeepSeek
  # https://api-docs.deepseek.com
  deepseek:
    base-url: https://api.deepseek.com/
    api-key:
    api-key-env: DEEPSEEK_API_KEY
    models:
      deepseek-chat:
        aliases: ["chat"]
        max-input-chars: 384000
      deepseek-reasoner:
        aliases: ["r1"]
        max-input-chars: 384000
  # GitHub Models
  # https://github.com/marketplace/models
  github-models:
    base-url: https://models.github.ai/inference
    api-key:
    api-key-env: GITHUB_PERSONAL_ACCESS_TOKEN
    models:
      openai/gpt-4.1:
        max-input-chars: 392000
      openai/o3-mini:
        max-input-chars: 392000
      openai/o4-mini:
        max-input-chars: 392000
      openai/text-embedding-3-large:
        max-input-chars: 392000
      openai/text-embedding-3-small:
        max-input-chars: 392000
      ai21-labs/AI21-Jamba-1.5-Large:
        max-input-chars: 392000
      ai21-labs/AI21-Jamba-1.5-Mini:
        max-input-chars: 392000
      cohere/cohere-command-a:
        max-input-chars: 392000
      cohere/Cohere-command-r:
        max-input-chars: 392000
      cohere/Cohere-command-r-08-2024:
        max-input-chars: 392000
      cohere/Cohere-command-r-plus:
        max-input-chars: 392000
      cohere/Cohere-command-r-plus-08-2024:
        max-input-chars: 392000
      cohere/Cohere-embed-v3-english:
        max-input-chars: 392000
      cohere/Cohere-embed-v3-multilingual:
        max-input-chars: 392000
      core42/jais-30b-chat:
        max-input-chars: 392000
      deepseek/DeepSeek-R1:
        max-input-chars: 392000
      deepseek/DeepSeek-V3-0324:
        max-input-chars: 392000
      meta/Llama-3.2-11B-Vision-Instruct:
        max-input-chars: 392000
      meta/Llama-3.2-90B-Vision-Instruct:
        max-input-chars: 392000
      meta/Llama-3.3-70B-Instruct:
        max-input-chars: 392000
      meta/Llama-4-Maverick-17B-128E-Instruct-FP8:
        max-input-chars: 392000
      meta/Llama-4-Scout-17B-16E-Instruct:
        max-input-chars: 392000
      meta/Meta-Llama-3.1-405B-Instruct:
        max-input-chars: 392000
      meta/Meta-Llama-3.1-70B-Instruct:
        max-input-chars: 392000
      meta/Meta-Llama-3.1-8B-Instruct:
        max-input-chars: 392000
      meta/Meta-Llama-3-70B-Instruct:
        max-input-chars: 392000
      meta/Meta-Llama-3-8B-Instruct:
        max-input-chars: 392000
      mistral-ai/Codestral-2501:
        max-input-chars: 392000
      mistral-ai/Ministral-3B:
        max-input-chars: 392000
      mistral-ai/Mistral-Large-2411:
        max-input-chars: 392000
      mistral-ai/mistral-medium-2505:
        max-input-chars: 392000
      mistral-ai/Mistral-Nemo:
        max-input-chars: 392000
      mistral-ai/mistral-small-2503:
        max-input-chars: 392000
      xai/grok-3:
        max-input-chars: 392000
      xai/grok-3-mini:
        max-input-chars: 392000
      microsoft/MAI-DS-R1:
        max-input-chars: 392000
      microsoft/Phi-3.5-mini-instruct:
        max-input-chars: 392000
      microsoft/Phi-3.5-MoE-instruct:
        max-input-chars: 392000
      microsoft/Phi-3.5-vision-instruct:
        max-input-chars: 392000
      microsoft/Phi-3-medium-128k-instruct:
        max-input-chars: 392000
      microsoft/Phi-3-medium-4k-instruct:
        max-input-chars: 392000
      microsoft/Phi-3-mini-128k-instruct:
        max-input-chars: 392000
      microsoft/Phi-3-mini-4k-instruct:
        max-input-chars: 392000
      microsoft/Phi-3-small-128k-instruct:
        max-input-chars: 392000
      microsoft/Phi-3-small-8k-instruct:
        max-input-chars: 392000
      microsoft/Phi-4:
        max-input-chars: 392000
      microsoft/Phi-4-mini-instruct:
        max-input-chars: 392000
      microsoft/Phi-4-mini-reasoning:
        max-input-chars: 392000
      microsoft/Phi-4-multimodal-instruct:
        max-input-chars: 392000
      microsoft/Phi-4-reasoning:
        max-input-chars: 392000
